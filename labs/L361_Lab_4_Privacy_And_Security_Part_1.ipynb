{"cells":[{"cell_type":"markdown","metadata":{"id":"hpQbkoayYCpj"},"source":["# 0. Marking.\n","\n","**_IMPORTANT_**: Save a copy of this notebook into your Drive before you start.\n","\n","- Please attempt all the questions marked for your group (Part II ✅ | Part III/MPhil ✅).\n","- Continue to part 2 after you are done with this one.\n","\n","Please submit a zip file, containing both parts, consiting of of:\n","\n","1. A text file with a publicly visible link to your notebooks in Google Colab or GitHub.\n","2. A downloaded copy (ipynb) of your notebooks or your zipped cloned GitHub repo. You may treat these as a report: we will not be re-executing the code you used to produce the answers unless required.\n","\n","If you find yourself enjoying the material, feel free to attempt more! Provide your answers in a new cell below the question cell.\n"]},{"cell_type":"markdown","metadata":{"id":"T_-VhIG0szzo"},"source":["## Imports\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":33419,"status":"ok","timestamp":1703272146651,"user":{"displayName":"Alexandru-Andrei Iacob","userId":"00751686620367198202"},"user_tz":-120},"id":"FuDMIMEUszzo","outputId":"a165116c-c435-40ca-9ef1-77bae5089f20"},"outputs":[],"source":["# The simulation component of flower uses RAY under the hood.\n","# `pip` could produce some errors. Nothing to worry about.\n","# The execution has been verified; it is working anyway.\n","! pip install --quiet --upgrade \"pip\"\n","! pip install --quiet git+https://github.com/Iacob-Alexandru-Andrei/flower.git@teaching ray==\"2.6.3\" torch torchvision  gdown tqdm seaborn torchsummary pycrypto pycryptodome cryptography tensorflow-privacy matplotlib"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OTAtWeP_szzp"},"outputs":[],"source":["# Imports\n","import csv\n","import numbers\n","import os\n","import random\n","import pickle\n","from collections import OrderedDict, defaultdict\n","from collections.abc import Callable\n","from copy import deepcopy\n","from pathlib import Path\n","from typing import Any\n","from logging import INFO\n","\n","\n","import flwr as fl\n","import ray\n","import gdown\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","import seaborn as sns\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from flwr.common import (\n","    log,\n","    Metrics,\n","    Config,\n","    GetPropertiesIns,\n","    GetPropertiesRes,\n","    MetricsAggregationFn,\n",")\n","from flwr.client import Client\n","from flwr.common.parameter import ndarrays_to_parameters, parameters_to_ndarrays\n","from flwr.common.typing import NDArrays, Parameters, Scalar\n","from flwr.server import ServerConfig, History\n","from flwr.server.server_returns_parameters import ReturnParametersServer as Server\n","from flwr.server.client_manager import SimpleClientManager\n","from flwr.server.client_proxy import ClientProxy\n","from flwr.server.criterion import Criterion\n","from flwr.server.strategy import Strategy\n","from PIL import Image\n","from PIL.Image import Image as ImageType\n","from torch.nn import Module\n","from torch.utils.data import DataLoader, Dataset, Subset\n","from torchvision import transforms\n","from tqdm import tqdm\n","from enum import IntEnum\n","from datetime import datetime, timezone\n","import json\n","\n","# Add new seeds here for easy autocomplete\n","\n","\n","class Seeds(IntEnum):\n","    DEFAULT = 1337\n","\n","\n","np.random.seed(Seeds.DEFAULT)\n","random.seed(Seeds.DEFAULT)\n","torch.manual_seed(Seeds.DEFAULT)\n","torch.backends.cudnn.benchmark = False\n","torch.backends.cudnn.deterministic = True\n","\n","PathType = Path | str | None"]},{"cell_type":"markdown","metadata":{"id":"2Sz3p_A0szzq"},"source":["### Paths\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3ELIXqK2szzp"},"outputs":[],"source":["home_dir = content if (content := Path(\"/content\")).exists() else Path.cwd()\n","dataset_dir: Path = home_dir / \"femnist\"\n","data_dir: Path = dataset_dir / \"data\"\n","centralized_partition: Path = dataset_dir / \"client_data_mappings\" / \"centralized\"\n","centralized_mapping: Path = dataset_dir / \"client_data_mappings\" / \"centralized\" / \"0\"\n","federated_partition: Path = dataset_dir / \"client_data_mappings\" / \"fed_natural\""]},{"cell_type":"markdown","metadata":{},"source":["### Useful Python functions\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def convert(o: Any) -> int | float:\n","    \"\"\"Convert input object to Python numerical if numpy.\"\"\"\n","    # type: ignore[reportGeneralTypeIssues]\n","    if isinstance(o, np.int32 | np.int64):\n","        return int(o)\n","    # type: ignore[reportGeneralTypeIssues]\n","    if isinstance(o, np.float32 | np.float64):\n","        return float(o)\n","    raise TypeError\n","\n","\n","def save_history(hist: History, name: str) -> None:\n","    \"\"\"Save history from simulation to file.\"\"\"\n","    time = int(datetime.now(timezone.utc).timestamp())\n","    path = home_dir / \"histories\"\n","    path.mkdir(exist_ok=True)\n","    path = path / f\"hist_{time}_{name}.json\"\n","    with open(path, \"w\", encoding=\"utf-8\") as f:\n","        json.dump(hist.__dict__, f, ensure_ascii=False, indent=4, default=convert)\n","\n","\n","def start_seeded_simulation(\n","    client_fn: Callable[[str], Client],\n","    num_clients: int,\n","    config: ServerConfig,\n","    strategy: Strategy,\n","    name: str,\n","    seed: int = Seeds.DEFAULT,\n","    iteration: int = 0,\n","    server: Server | None = None,\n",") -> tuple[list[tuple[int, NDArrays]], History]:\n","    \"\"\"Wrap simulation to always seed client selection.\"\"\"\n","    np.random.seed(seed ^ iteration)\n","    torch.manual_seed(seed ^ iteration)\n","    random.seed(seed ^ iteration)\n","    parameter_list, hist = fl.simulation.start_simulation_no_ray(\n","        client_fn=client_fn,\n","        num_clients=num_clients,\n","        client_resources={},\n","        config=config,\n","        strategy=strategy,\n","        server=server,\n","    )\n","    save_history(hist, name)\n","    return parameter_list, hist"]},{"cell_type":"markdown","metadata":{"id":"RJ9VT7Fzszzp"},"source":["### Dataset\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#  Download compressed dataset\n","if not (home_dir / \"femnist.tar.gz\").exists():\n","    file_id = \"1-CI6-QoEmGiInV23-n_l6Yd8QGWerw8-\"\n","    gdown.download(\n","        f\"https://drive.google.com/uc?export=download&confirm=pbef&id={file_id}\",\n","        str(home_dir / \"femnist.tar.gz\"),\n","    )\n","\n","# Decompress dataset\n","if not dataset_dir.exists():\n","    !tar -xf {str(home_dir)}/femnist.tar.gz -C {str(home_dir)} 2> /dev/null\n","    log(INFO, f\"Dataset extracted in {dataset_dir}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if not (home_dir / \"common\").exists():\n","    ! git clone \"https://github.com/camlsys/L361-Federated-Learning.git\" temp_repo\n","\n","    # Copy the folder to the current directory\n","    ! cp -r \"temp_repo/labs/common\" {home_dir}\n","\n","    # Delete the cloned repository\n","    ! rm -rf temp_repo\n","\n","    # Create the __init__.py file\n","    (home_dir / \"__init__.py\").open(mode=\"a+\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xlpr4Y69szzq"},"outputs":[],"source":["from common.client import FlowerClient, get_flower_client_generator\n","from common.client_manager import CustomClientManager\n","from common.strategy import DeterministicSampleFedAvg as FedAvgM\n","from common.client_utils import (\n","    get_network_generator_cnn,\n","    get_model_parameters,\n","    aggregate_weighted_average,\n","    get_federated_evaluation_function,\n","    get_default_test_config,\n","    get_default_train_config,\n","    get_device,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VDY-yJYPszzp"},"outputs":[],"source":["# Download the compressed dataset\n","if not (home_dir / \"femnist.tar.gz\").exists():\n","    id = \"1-CI6-QoEmGiInV23-n_l6Yd8QGWerw8-\"\n","    gdown.download(\n","        f\"https://drive.google.com/uc?export=download&confirm=pbef&id={id}\",\n","        str(home_dir / \"femnist.tar.gz\"),\n","    )\n","\n","# Decompress dataset\n","if not dataset_dir.exists():\n","    !tar -xf {str(home_dir)}/femnist.tar.gz -C {str(home_dir)} 2> /dev/null\n","    log(INFO, \"Dataset extracted in %s\", dataset_dir)"]},{"cell_type":"markdown","metadata":{"id":"iPF0-Nlmszzo"},"source":["# 1. Introduction.\n"]},{"cell_type":"markdown","metadata":{"id":"CyT284y4DPc9"},"source":["Welcome to the fourth lab session in our FL course. Having explored standard FL, data heterogeneity and device heterogeneity, we now focus on one of FL's main selling points: privacy.\n","\n","The two methods for achieving privacy we will explore are client-level [**Differential Privacy**](https://ieeexplore.ieee.org/abstract/document/9069945) and [**Secure Aggregation**](https://research.google/pubs/pub45808/). Intuitively, the **first** provides statistical guarantees on how distinguishable a single client's pseudo-gradient is compared to the aggregated pseudo-gradient without its contribution.\n","\n","<!-- a probabilistic bound on how distinct the final model trained using the data of a given client would be from the same model trained without data from that client (thus if a client contains all samples from a given class, it should be difficult for the model to predict that class as it would have to violate DP).  -->\n","\n","In an ideal privacy scenario, we would prefer it if two global models trained with or without the data of a given client were indistinguishable.\n","The **second** is a cryptography-based solution that effectively erases the ability to identify a client during aggregation by encrypting all client model updates to produce the correct aggregate when summed.\n","\n","As these topics are pretty in-depth, we will not cover them to the same level of detail as previous labs concerning theoretical subjects (such as data heterogeneity in lab 2). This lab will be primarily experimental to test the algorithms put into practice. We will, however, begin with a light introduction. Suppose you are interested in learning more about the subject. In that case, we may recommend the following papers [Deep Learning with Differential Privacy](https://arxiv.org/pdf/1607.00133.pdf) \\[1], [Learning Differentially Private Recurrent Language Models](https://arxiv.org/pdf/1710.06963.pdf) \\[2] and [Differentially private learning with adaptive clipping](https://arxiv.org/abs/1905.03871) \\[3] on the DP front. For secure aggregation consider the original paper [Practical Secure Aggregation for Federated Learning on User-Held Data](https://arxiv.org/pdf/1611.04482.pdf) \\[4] and the improved [LightSecAgg](https://arxiv.org/abs/2109.14236) \\[5].\n","\n","Secure aggregation does not harm the model's accuracy and demands only increased communication. Any samples involved in training may still be reconstructed in an attack; however, knowing who contributed the samples will not be possible. Thus, while the implementation is complex, its behaviour is predictable and shall be reserved for the end of the notebook as we are only concerned with measuring communication costs and answering conceptual questions. As such, let us dive into Differential Privacy after the following well-known imports.\n","\n","> **Important** The entire notebook has been tested in a GPU-enabled Google Colab environment, which runs at around 6 minutes per FL experiment. All experiments require you to vary at most one parameter at a time, so please use a for loop to generate a list of histories rather than trying to manage multiple cells---most experiments rely on one run we create for demonstration purposes to cover one of the desire parameter values. We have purposefully reduced the size of the federated test set significantly and have also reduced the overall number of clients used during FL experimentation. If you are more constrained in your resources (e.g., you have run out of Google accounts that can get a GPU or you get an error peculiar to your exact colab machine), let us know either on Slack or in your submission, and we will either help you set up the code locally, potentially provide you with history objects, or offer take this into account during marking.\n","\n","Citations:\n","\n","1.  Abadi, Martin, et al. \"Deep learning with differential privacy.\" Proceedings of the 2016 ACM SIGSAC conference on computer and communications security. 2016.\n","2.  McMahan, H. Brendan, et al. \"Learning differentially private recurrent language models.\" arXiv preprint arXiv:1710.06963 (2017).\n","3.  Thakkar, Om, Galen Andrew, and H. Brendan McMahan. \"Differentially private learning with adaptive clipping.\" arXiv e-prints (2019): arXiv-1905.\n","4.  Bonawitz, Keith, et al. \"Practical secure aggregation for federated learning on user-held data.\" arXiv preprint arXiv:1611.04482 (2016).\n","5.  So, Jinhyun, et al. \"Lightsecagg: a lightweight and versatile design for secure aggregation in federated learning.\" Proceedings of Machine Learning and Systems 4 (2022): 694-720.\n"]},{"cell_type":"markdown","metadata":{"id":"QNk0A-eD4cDQ"},"source":["# 2.Deep Learning With Differential Privacy\n"]},{"cell_type":"markdown","metadata":{"id":"oo1rQI9y4gum"},"source":["Before diving into a definition of Differential Privacy adapted to an FL context, we shall begin with the first version of DP applied to Deep Learning based on the aforementioned paper.\n","\n","The authors of the original extension of _DP to Deep Learning_ justify the need for such a privacy mechanism based on the possibility that an attacker may reconstruct specific samples from the data perfectly in a sensitive context, such as facial recognition, while only having **black-box** access to the trained model. However, their algorithm for DP protects against even adversaries with full knowledge of the training procedure, access to the parameters and potential control over parts of the dataset.\n","\n","Their **definition** of DP is as follows: a randomised mechanism $M: D ⟶ R$ (a neural network training procedure, in our case) satisfies $(ϵ,δ)$-differential privacy for any $S⊆R$ (a subset of outputs in the range $R$) if $Pr[M(d) \\in S] \\leq e^{\\epsilon} Pr[M(d') \\in S] + \\delta$ holds, where $d∈D$ and $d'∈D$ are adjacent sets (datasets) of the same domain $D$ (set of all the possible datasets), i.e., they differ by only one record (a training sample, in our case). We can **interpret** this as stating that the probability of getting a particular output from our model when not including a specific sample should be close to the probability of getting the same output had we not included the sample. Specifically, when $\\epsilon=0$, the two probabilities are equal, and it is impossible to find out if that sample was included in the training set. The bigger $\\epsilon$ is the lower protection is. The probability that the model produces different outputs when trained on adjacent datasets increases exponentially with $\\epsilon$.\n","\n","> Importantly, the original definition of DP and the one you may have encountered before only contained the exponential term _without the_ $\\delta$; however, this resulted in _very strong requirements_ for not breaking privacy. This new form, $(\\epsilon, \\delta)$ privacy relaxed the requirement. Informally, it can be interpreted as allowing privacy at a given $\\epsilon$ level to be broken with _probability_ $1-\\delta$. We do not have the scale of experimentation necessary to consider both in this lab, as such we will focus on $\\epsilon$ values at the detriment of analysing changes in $\\delta$. For the experiments in this lab, you can consider DP to be defined entirely in terms of ϵ. Formally, the transition to $(\\epsilon, \\delta)$ delta was necessary to move from an inefficient noise generation mechanism to Gaussian noise as ML models are much more complex than typical vector-valued functions.\n"]},{"cell_type":"markdown","metadata":{"id":"-QwrOIl5_SK8"},"source":["Differentially private **approximations** of functions are usually **constructed** by the addition of noise proportional to the sensitivity of the function---think of it as the maximal impact that the addition or removal of a data point can have upon the output of the function. From now on, we shall refer to this noise level as the **`noise_multiplier`** as it scales the noise multiplicatively based on the sensitivity. When DP was extended to a DL context, making the system differentially private by intervening upon the gradients used during training rather than the final model was significantly more straightforward than operating on the model as a function after training. In the context of ML model updates (gradient descent steps or pseudo-gradients in FL), their sensitivity is generally defined in terms of the l2 norm (when noise is Gaussian) of the update, and the noise is thus scaled based on this norm.\n","\n","As such, the **original DP-SGD** operates as follows:\n","\n","1.  _Compute_ the derivative concerning each sample (not minibatch).\n","2.  _Clip_ the L2 norm of the derivative so it falls below a given bound.\n","3.  _Aggregate_ these clipped derivatives and _add_ Gaussian _noise_ to obfuscate the impact of specific samples used to compute the gradients. Here, the noise is proportional to the L2 bound.\n","\n","Suppose we reframe DP to the original context of databases and records. In that case, the larger the number of noisy answers the database offers, the more an attacker can eliminate the noise by looking at the entire distribution of answers. Similarly, the more samples out of the total an ML model sees (or the more times it sees the same sample), the more the noise of the sample gradients average out. For a model to be trained for an extended period, it is thus necessary to use a higher `noise_multiplier`. We shall soon extend this trade-off to clients within an FL context.\n","\n","While this process operates reasonably in the context of centralised, applying DP-SGD on every client in FL is **problematic**, given the reduced efficiency of the training method. As a result of this inefficiency, the federated model will likely incur significant drops in its already low performance. Furthermore, multiple studies have confirmed that applying DP locally has disastrous effects on the accuracy of the final federated model.\n"]},{"cell_type":"markdown","metadata":{"id":"dMV6nFEaszzq"},"source":["# 3.User-level Differential Privacy\n"]},{"cell_type":"markdown","metadata":{"id":"UjeLJSKrGTk9"},"source":["Differential privacy at a client/user level in FL follows the same **definition**, except adjacent datasets are constructed by adding or removing all samples from a given client. Thus, under _maximum privacy scenarios_, with $\\epsilon=0$ and $\\delta=0$, two models should behave identically regardless of the presence of a specific user in the federation. For user-level DP, training with more users (rather than samples) results in the degradation of privacy. Thus, the **`noise_multiplier`** necessary to make an FL system differentially private with respect to an L2 norm bound depends on the total number of users, the number of users sampled every round and the number of rounds.\n","\n","**DP-FedAvg** represents a reasonably direct analogue to DP-SGD as it applies the same process to FL pseudo-gradients that DP-SGD applies to gradients generated by one sample. Namely, it clips the gradients based on the L2 norm on the local client after training. The server then adds Gaussian noise related to the L2 norm bound via the `noise_multiplier` when it receives the gradients.\n","\n","However, this extension is hampered by the fact that DP-SGD assumes an IID distribution of samples. As we, clients in FL contain **non-IID data** and have skewed numbers of samples. As such, for the theoretical privacy guarantee to hold DP-FedAvg **must assume** that _clients will not drop_ out and that the overall set of available clients in the population is static---both being significant limitations. Furthermore, _unweighted aggregation_ is usually enforced since weighted aggregation is more likely to leak data from a specific user. An _additional note_ worth making is that even when violating the theoretical assumptions of DP, applying noise and clipping gradients is still likely to make reconstructing data belonging to a specific client more difficult in practice.\n","\n","One final theoretical concern worth addressing prior to experimentation is the **nature of the L2 norm clipping**. Two specific _questions_ arise in the early works discussing DP-FedAvg:\n","\n","- Should the clipping be done per layer or uniformly across the entire model? Consider scenarios where a single large layer encodes all the relevant information about a specific user and is not clipped because the overall L2 norm of the gradient is lower than a generic bound.\n","- How should a L2 bound be chosen and changed? If the model updates are too small, the model is less likely to learn. However, a more oversized bound implies more noise and thus leads to potential degradation yet again.\n","\n","These questions have been answered by follow-up work. On the _first point_, this stack overflow answer by one of the authors of paper \\[3] above indicates that per-layer bounding leads to worse performance as it is harsher for little benefit. On the _second point_, methods for efficiently tracking a given quantile of the L2 distribution amongst client updates were proposed in \\[3]. We will glance at this adaptive mechanism in today's lab but shall not examine it in detail.\n"]},{"cell_type":"markdown","metadata":{"id":"WLnBr0hNVrDN"},"source":["**Question 1 (Part II ✅ | Part III/MPhil ✅):**\n","\n","(This is a conceptual question. Please do not provide more than three sentences per sub-question.)\n","\n","Consider two applications of FL, next-word prediction and image classification based on personal user data from smartphones.\n","\n","1. What kind of sensitive information could be extracted from models trained on these tasks?\n","2. How would DP help preserve privacy for each task when applied on a per-sample versus per-client-dataset level?\n"]},{"cell_type":"markdown","metadata":{"id":"GynLLgmuDvJc"},"source":["**Question 2 (Part III/MPhil ✅):**\n","\n","(This is a **short** conceptual question. Please do not provide more than four sentences as an answer.)\n","\n","Considering a scenario of a multimodal LLM that may or may not have been trained on your images, how would you test for privacy leakage given access to:\n","\n","1.  Only a chat UI to interact with the model.\n","2.  The full model and all of your data that could have gone into it.\n"]},{"cell_type":"markdown","metadata":{"id":"KZJC77bkGAsd"},"source":["## 3.1 Fixed Norm Bound DP\n","\n","Given the highly abstract definition of privacy that DP uses, could you think of ways to test the effectiveness of DP practically?\n"]},{"cell_type":"markdown","metadata":{"id":"ICiFR-C3szzq"},"source":["We shall begin by implementing the `DPFedAvg` strategy based on the description above using a static bound on the L2 norm of clients. While we could near-effortlessly add client-level Differential Privacy by using wrappers provided by Flower, implementing its components should be straightforward and informative.\n","\n","The first cell provides utilities for gradient clipping and noise injection. The clipping operates via simple multiplication.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vz-8GaN1szzq"},"outputs":[],"source":["def compute_model_delta(\n","    trained_parameters: NDArrays, og_parameters: NDArrays\n",") -> NDArrays:\n","    \"\"\"Compute the delta between two sets of parameters.\"\"\"\n","    return [\n","        np.subtract(x, y)\n","        for (x, y) in zip(trained_parameters, og_parameters, strict=True)\n","    ]\n","\n","\n","def compute_norm(update: NDArrays) -> float:\n","    \"\"\"Compute the l2 norm of a parameter update.\n","\n","    It will account for mismatched NumPy array shapes, to be used in clipping.\n","    \"\"\"\n","    flat_update = update[0]\n","    for i in range(1, len(update)):\n","        flat_update = np.append(flat_update, update[i])\n","    squared_update = np.square(flat_update)\n","    norm_sum = np.sum(squared_update)\n","    norm = np.sqrt(norm_sum)\n","    return norm\n","\n","\n","def clip_by_l2(update: NDArrays, threshold: float) -> tuple[NDArrays, bool]:\n","    \"\"\"Scales the update so thats its L2 norm is upper-bound to threshold.\"\"\"\n","    update_norm = compute_norm(update)\n","    scaling_factor = min(1, threshold / update_norm)\n","    update_clipped: NDArrays = [layer * scaling_factor for layer in update]\n","    return update_clipped, (scaling_factor < 1)\n","\n","\n","def add_gaussian_noise(update: NDArrays, std_dev: float) -> NDArrays:\n","    \"\"\"Add Gaussian noise to each floating point value.\"\"\"\n","    update_noised = [\n","        layer + np.random.normal(0, std_dev, layer.shape) for layer in update\n","    ]\n","    return update_noised"]},{"cell_type":"markdown","metadata":{"id":"HZ4oyylaYSED"},"source":["These components are all we need to design a DP client which can add noise to its updates according to parameters received from the strategy. According to the evaluated threat model, the flower implementation allows noise injection to be equivalently done on the client or server. We shall assume a trustworthy server for this lab and eschew adding noise on the clients.\n","\n","The client training procedure shall follow the description above verbatim and proceed as follows:\n","\n","1.  The client receives the parameters and standard configuration arguments as in previous labs.\n","2.  It also receives a maximum bound on the L2 norm of the trained model.\n","3.  The model is trained, and the client computes the delta or **update** between its parameters and the original ones received.\n","4.  The client computes the ratio between the L2 norm of its local update and the maximum it received. It then rescales all the weights in the update by this ratio, so the final norm is at-most the bound---since $||\\alpha \\times w||_2 = |\\alpha| \\times ||w||_2$.\n","5.  The client applies the clipped update to the original parameters and potentially adds Gaussian noise---if this does not already happen on the server---before returning them.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21138,"status":"ok","timestamp":1703272167787,"user":{"displayName":"Alexandru-Andrei Iacob","userId":"00751686620367198202"},"user_tz":-120},"id":"jg6mnpsM8Rl9","outputId":"2ec9e475-5d65-422a-999b-54fb7e8d090f"},"outputs":[],"source":["np.random.seed(Seeds.DEFAULT)\n","random.seed(Seeds.DEFAULT)\n","torch.manual_seed(Seeds.DEFAULT)\n","network_generator_cnn = get_network_generator_cnn()\n","seed_net_cnn = network_generator_cnn()\n","seed_model_cnn_params: NDArrays = get_model_parameters(seed_net_cnn)\n","federated_evaluation_function = get_federated_evaluation_function(\n","    data_dir=data_dir,\n","    centralized_mapping=centralized_mapping,\n","    device=get_device(),\n","    batch_size=get_default_test_config()[\"batch_size\"],\n","    num_workers=get_default_test_config()[\"num_workers\"],\n","    model_generator=network_generator_cnn,\n","    criterion=nn.CrossEntropyLoss(),\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eaj-oumAszzq"},"outputs":[],"source":["# Based on the original implementation by Vasundhara Agarwal\n","class DPFlowerRayClient(FlowerClient):\n","    \"\"\"Extends the FlowerClient class to implement DP-FedAvg.\"\"\"\n","\n","    def fit(\n","        self, parameters: NDArrays, config: dict[str, Scalar], **kwargs: dict[str, Any]\n","    ) -> tuple[NDArrays, int, dict]:\n","        \"\"\"Receive and train a model on the local client data.\n","\n","        It uswa parameters from the config dict while injecting gaussian noise into the\n","        parameter update.\n","\n","        Args:\n","            net (NDArrays): Pytorch model parameters\n","            config (dict[str, Scalar]): Dictionary describing the training parameters\n","\n","        Returns\n","        -------\n","            tuple[NDArrays, int, dict]: Returns the updated model, the size of the\n","                local dataset and other metrics\n","        \"\"\"\n","        # Create a copy of the initial parameters\n","        og_parameters = deepcopy(parameters)\n","\n","        # Only create model right before training/testing\n","        # To lower memory usage when idle\n","        net = self.set_parameters(parameters)\n","        net.to(self.device)\n","        train_loader: DataLoader = self._create_data_loader(\n","            config, name=\"train\", **kwargs\n","        )\n","        train_loss = self._train(\n","            net, train_loader=train_loader, config=config, **kwargs\n","        )\n","\n","        # Metrics dict since the DP strategy requires an indicator\n","        # to be returned if the model updates was not clipped on the client\n","        # and should be clipped on the server\n","        metrics = {\"train_loss\": train_loss}\n","\n","        trained_parameters = get_model_parameters(net)\n","        # Calculate the delta between the two models\n","        model_update = [\n","            np.subtract(x, y)\n","            for (x, y) in zip(trained_parameters, og_parameters, strict=True)\n","        ]\n","\n","        # Clip the delta so all of the updates fall bellow\n","        # The same norm\n","        model_update, clipped = clip_by_l2(model_update, config[\"dpfedavg_clip_norm\"])\n","\n","        if \"dpfedavg_noise_stddev\" in config:\n","            # Noising\n","            model_update = add_gaussian_noise(\n","                model_update, config[\"dpfedavg_noise_stddev\"]\n","            )\n","\n","        for i, _ in enumerate(og_parameters):\n","            trained_parameters[i] = og_parameters[i] + model_update[i]\n","\n","        # Calculating value of norm indicator bit, required for adaptive clipping\n","        if \"dpfedavg_adaptive_clip_enabled\" in config:\n","            if not isinstance(config[\"dpfedavg_adaptive_clip_enabled\"], bool):\n","                raise Exception(\n","                    \"dpfedavg_adaptive_clip_enabled should be a boolean-valued flag.\"\n","                )\n","            metrics[\"dpfedavg_norm_bit\"] = not clipped\n","\n","        return trained_parameters, len(train_loader), metrics"]},{"cell_type":"markdown","metadata":{"id":"e6TB5vmhp0u0"},"source":["The following cell will construct a generator for this client class capable of filtering participants with less than one batch of data. This is necessary to avoid failures as \"DPFedAvg\" is not tolerant of dropouts.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1631,"status":"ok","timestamp":1703272169417,"user":{"displayName":"Alexandru-Andrei Iacob","userId":"00751686620367198202"},"user_tz":-120},"id":"XIfz9DNHp0u0","outputId":"8c8aa593-f13d-4a04-ae15-ee5401f04c8b"},"outputs":[],"source":["fl_client_gen = get_flower_client_generator(\n","    network_generator_cnn, federated_partition, data_dir\n",")\n","client_to_num_sample: list[tuple[int, int]] = [\n","    (cid, fl_client_gen(i).get_train_set_size()) for i, cid in enumerate(range(3229))\n","]\n","client_samples_dataframe = pd.DataFrame(\n","    client_to_num_sample, columns=[\"cid\", \"n_samples\"]\n",")\n","\n","# Remove clients with less than 32 samples corresponding to the default batch size\n","min_n_samples = 32\n","client_samples_dataframe.drop(\n","    client_samples_dataframe[client_samples_dataframe.n_samples < min_n_samples].index,\n","    inplace=True,\n",")\n","client_samples_dataframe.reset_index(drop=True)\n","num_total_clients = len(client_samples_dataframe)\n","log(INFO, \"Num total clients: %s\", num_total_clients)\n","\n","\n","def get_DP_client_generator(\n","    model_generator: Callable[[], Module],\n","    data_dir: Path,\n","    partition_dir: Path,\n","    mapping_fn: Callable[[int], int] | None = lambda x: client_samples_dataframe.cid[x],\n",") -> Callable[[str], FlowerClient]:\n","    \"\"\"Wrap function for the client instance generator.\n","\n","    This provides the client generator with a model generator function.\n","    Also, the partition directory must be passed.\n","    A mapping function could be used for filtering/ordering clients.\n","\n","    Args:\n","        data_dir (Path): path to the dataset folder.\n","        model_generator (Callable[[], Module]): model generator function.\n","        partition_dir (Path): directory containing the partition.\n","        mapping_fn (Optional[Callable[[int], int]]): function mapping sorted/filtered\n","            ids to real cid.\n","\n","    Returns\n","    -------\n","        Callable[[str], FlowerRayClient]: client instance.\n","    \"\"\"\n","\n","    def client_fn(cid: str) -> DPFlowerRayClient:\n","        \"\"\"Create a single client instance given the client id `cid`.\n","\n","        Args:\n","            cid (str): client id, Flower requires this to of type str.\n","\n","        Returns\n","        -------\n","            FlowerRayClient: client instance.\n","        \"\"\"\n","        return DPFlowerRayClient(\n","            cid=mapping_fn(int(cid)) if mapping_fn is not None else int(cid),\n","            data_dir=data_dir,\n","            partition_dir=partition_dir,\n","            model_generator=model_generator,\n","        )\n","\n","    return client_fn"]},{"cell_type":"markdown","metadata":{"id":"j3UctBISKe_L"},"source":["This DP client encapsulates all the meaningful work required for client-level differential privacy to be carried out. However, the strategy controls the L2 norm bound and the noise multiplier used to determine the Gaussian noise standard deviation based on this bound.\n","\n","We shall now implement a strategy capable of orchestrating DP clients in a manner which best preserves privacy within a given budget.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fQKfnfb7Q_Jj"},"outputs":[],"source":["from collections.abc import Callable\n","\n","from logging import INFO\n","\n","import numpy as np\n","\n","from flwr.common import (\n","    FitIns,\n","    EvaluateIns,\n","    FitRes,\n","    EvaluateRes,\n","    MetricsAggregationFn,\n","    NDArrays,\n","    Parameters,\n","    Scalar,\n",")\n","from flwr.common.logger import log\n","from math import sqrt\n","\n","\n","# Based on the original implementation by Vasundhara Agarwal\n","class DPFedAvgFixed(FedAvgM):\n","    \"\"\"Configurable FedAvg strategy implementation.\"\"\"\n","\n","    # pylint: disable=too-many-arguments,too-many-instance-attributes,line-too-long\n","    def __init__(\n","        self,\n","        *,\n","        fraction_fit: float = 1.0,\n","        fraction_evaluate: float = 1.0,\n","        min_fit_clients: int = 2,\n","        min_evaluate_clients: int = 2,\n","        min_available_clients: int = 2,\n","        evaluate_fn: (\n","            Callable[\n","                [int, NDArrays, dict[str, Scalar]],\n","                tuple[float, dict[str, Scalar]] | None,\n","            ]\n","            | None\n","        ) = None,\n","        on_fit_config_fn: Callable[[int], dict[str, Scalar]] | None = None,\n","        on_evaluate_config_fn: Callable[[int], dict[str, Scalar]] | None = None,\n","        accept_failures: bool = False,\n","        initial_parameters: Parameters | None = None,\n","        fit_metrics_aggregation_fn: MetricsAggregationFn | None = None,\n","        evaluate_metrics_aggregation_fn: MetricsAggregationFn | None = None,\n","        server_learning_rate: float = 1.0,\n","        server_momentum: float = 0.0,\n","        num_clients_per_round: int,\n","        clip_norm: float,\n","        noise_multiplier: float = 1,\n","        server_side_noising: bool = True,\n","    ) -> None:\n","        super().__init__(\n","            fraction_fit=fraction_fit,\n","            fraction_evaluate=fraction_evaluate,\n","            min_fit_clients=min_fit_clients,\n","            min_evaluate_clients=min_evaluate_clients,\n","            min_available_clients=min_available_clients,\n","            evaluate_fn=evaluate_fn,\n","            on_fit_config_fn=on_fit_config_fn,\n","            on_evaluate_config_fn=on_evaluate_config_fn,\n","            accept_failures=accept_failures,\n","            initial_parameters=initial_parameters,\n","            fit_metrics_aggregation_fn=fit_metrics_aggregation_fn,\n","            evaluate_metrics_aggregation_fn=evaluate_metrics_aggregation_fn,\n","            server_learning_rate=server_learning_rate,\n","            server_momentum=server_momentum,\n","        )\n","        # Doing fixed-size subsampling as in https://arxiv.org/abs/1905.03871\n","        self.num_clients_per_round = num_clients_per_round\n","        self.noise_multiplier = noise_multiplier\n","        self.server_side_noising = server_side_noising\n","        self.clip_norm = clip_norm\n","\n","    # Automatically calculate the standard deviation of the noise\n","    # Based on the clip norm and number of clients per round\n","    # The noise multiplier controls the number of standard deviations from the mean\n","    def _calc_client_noise_stddev(self) -> float:\n","        stddev = (\n","            self.noise_multiplier * self.clip_norm / (sqrt(self.num_clients_per_round))\n","        )\n","        return float(stddev)\n","\n","    def configure_fit(\n","        self,\n","        server_round: int,\n","        parameters: Parameters,\n","        client_manager: CustomClientManager,\n","    ) -> list[tuple[ClientProxy, FitIns]]:\n","        \"\"\"Configure the next round of training.\"\"\"\n","        config = {}\n","        if self.on_fit_config_fn is not None:\n","            # Custom fit config function provided\n","            config = self.on_fit_config_fn(server_round)\n","\n","        # Add DP info to config for local update clipping\n","        config[\"dpfedavg_clip_norm\"] = self.clip_norm\n","        if not self.server_side_noising:\n","            config[\"dpfedavg_noise_stddev\"] = self._calc_client_noise_stddev()\n","        fit_ins = FitIns(parameters, config)\n","\n","        # Sample clients\n","        sample_size, min_num_clients = self.num_fit_clients(\n","            client_manager.num_available()\n","        )\n","        clients = client_manager.sample(\n","            num_clients=sample_size,\n","            min_num_clients=min_num_clients,\n","            server_round=server_round,\n","        )\n","\n","        # Return client/config pairs\n","        return [(client, fit_ins) for client in clients]\n","\n","    def aggregate_fit(\n","        self,\n","        server_round: int,\n","        results: list[tuple[ClientProxy, FitRes]],\n","        failures: list[tuple[ClientProxy, FitRes] | BaseException],\n","    ) -> tuple[Parameters | None, dict[str, Scalar]]:\n","        \"\"\"Aggregate the results of the training round.\"\"\"\n","        if failures and not self.accept_failures:\n","            return None, {}\n","        # Forcing unweighted aggregation, as in https://arxiv.org/abs/1905.03871\n","        # By setting the number of examples associated to each model\n","        # To 1\n","        for _, fit_res in results:\n","            fit_res.num_examples = 1\n","            if self.server_side_noising:\n","                fit_res.parameters = ndarrays_to_parameters(\n","                    add_gaussian_noise(\n","                        parameters_to_ndarrays(fit_res.parameters),\n","                        self._calc_client_noise_stddev(),\n","                    )\n","                )\n","\n","        return super().aggregate_fit(server_round, results, failures)"]},{"cell_type":"markdown","metadata":{"id":"F5OgozgrFI0k"},"source":["Do observe how the unweighted aggregation combines with the norm clipping to limit the disproportionate impact of high-data clients upon the federated model to treat all clients close-to-equally regarding privacy leaks.\n","\n","We can now create a function to run such experiments, allowing you to easily maintain and change default parameters as needed.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KdbkwM6SVxFL"},"outputs":[],"source":["dp_client_generator = get_DP_client_generator(\n","    network_generator_cnn,\n","    data_dir,\n","    federated_partition,\n","    lambda x: client_samples_dataframe.cid[x],\n",")\n","default_parameters: dict = {\n","    \"train_config\": get_default_train_config(),\n","    \"test_config\": get_default_test_config(),\n","    \"num_total_clients\": num_total_clients,\n","    \"num_clients_per_round\": 4,\n","    \"num_evaluate_clients\": 0,\n","    \"num_evaluate\": 0,\n","    \"accept_failures\": False,\n","    \"min_fit_clients\": 2,\n","    \"min_available_clients\": 2,\n","    \"initial_parameters\": ndarrays_to_parameters(seed_model_cnn_params),\n","    \"client_generator\": dp_client_generator,\n","    \"seed\": Seeds.DEFAULT,\n","    \"num_rounds\": 30,\n","    \"strategy\": DPFedAvgFixed,\n","    \"fed_eval\": True,\n","    \"server_side_noising\": True,\n","}\n","\n","\n","def run_DP_fixed_fl(\n","    clip_norm: float = 4.0,\n","    noise_multiplier: float = 0.05,\n","    default_parameters: dict = default_parameters,\n","    **kwargs: dict[str, Any],\n",") -> Any:\n","    \"\"\"Execute a DP-FedAvg simulation with fixed clip norm and noise multiplier.\"\"\"\n","    parameters: dict = {**default_parameters, **kwargs}\n","\n","    def on_fit_config_fn(cid: int) -> dict[str, Scalar]:\n","        return parameters[\"train_config\"]\n","\n","    def on_evaluate_config_fn(cid: int) -> dict[str, Scalar]:\n","        return parameters[\"test_config\"]\n","\n","    fraction_fit: float = (\n","        float(parameters[\"num_clients_per_round\"]) / parameters[\"num_total_clients\"]\n","    )\n","    fraction_evaluate: float = (\n","        float(parameters[\"num_evaluate_clients\"]) / parameters[\"num_total_clients\"]\n","    )\n","\n","    strategy = parameters[\"strategy\"](\n","        num_clients_per_round=parameters[\"num_clients_per_round\"],\n","        fraction_fit=fraction_fit,\n","        fraction_evaluate=fraction_evaluate,\n","        min_fit_clients=parameters[\"min_fit_clients\"],\n","        min_available_clients=parameters[\"min_available_clients\"],\n","        on_fit_config_fn=on_fit_config_fn,\n","        on_evaluate_config_fn=on_evaluate_config_fn,\n","        initial_parameters=parameters[\"initial_parameters\"],\n","        accept_failures=parameters[\"accept_failures\"],\n","        evaluate_fn=(\n","            federated_evaluation_function if parameters[\"fed_eval\"] is True else None\n","        ),\n","        fit_metrics_aggregation_fn=aggregate_weighted_average,\n","        evaluate_metrics_aggregation_fn=aggregate_weighted_average,\n","        clip_norm=clip_norm,\n","        noise_multiplier=noise_multiplier,\n","        server_side_noising=parameters[\"server_side_noising\"],\n","    )\n","    client_manager = CustomClientManager(criterion=None, seed=parameters[\"seed\"])\n","    server = Server(\n","        client_manager=client_manager,\n","        strategy=strategy,\n","    )\n","    return start_seeded_simulation(\n","        client_fn=lambda cid: parameters[\"client_generator\"](cid).to_client(),\n","        num_clients=parameters[\"num_total_clients\"],\n","        server=server,\n","        config=ServerConfig(num_rounds=parameters[\"num_rounds\"]),\n","        strategy=strategy,\n","        seed=parameters[\"seed\"],\n","        name=f\"fixed_clip_norm_{clip_norm}_noise_{noise_multiplier}\",\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":165397,"status":"ok","timestamp":1703272334810,"user":{"displayName":"Alexandru-Andrei Iacob","userId":"00751686620367198202"},"user_tz":-120},"id":"x-_BWzXRdd12","outputId":"495d6c88-b662-40a8-fbdd-7405b9e2b7f6"},"outputs":[],"source":["parameters_for_every_round, hist_clip_bound_4_noise_0_05 = run_DP_fixed_fl(4)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":287,"status":"ok","timestamp":1703272335091,"user":{"displayName":"Alexandru-Andrei Iacob","userId":"00751686620367198202"},"user_tz":-120},"id":"2PlItuFGYJ-n","outputId":"b934a8d4-33ea-43da-869a-3677b6d15b1d"},"outputs":[],"source":["hist_clip_bound_4_noise_0_05"]},{"cell_type":"markdown","metadata":{"id":"uISxIgrgBS3P"},"source":["**Question 3 (Part II ✅ | Part III/MPhil ✅):**\n","\n","(You must provide the answer with **code** and **plots** for this question. A short written argumentation is recommended.)\n","\n","Norm-clipping is an often-used technique in FL that resembles the previously discussed FedProx---or FedAvg with a `server_learning_rate<1.0`. When it is used to tackle data heterogeneity, it limits the divergence of highly heterogeneous clients. In the context of privacy, more significant updates are likely to come from either larger or more heterogeneous clients. Thus, when combined with unweighted aggregation, norm clipping stabilises training. However, it may slow down improvements in accuracy.\n","\n","> It is important to note that, theoretically, the triangle inequality assures us that the overall federated model update will have a norm below `clip_norm`.\n","\n","You will now examine the effects of norm-clipping on model accuracy irrespective of noise.\n","\n","1. Use one round of federated training with `num_clients_per_round=50` to empirically derive a **very rough baseline** of the average L2 norm at the beginning of training. Modify the client `fit` function to return in the metrics dictionary the L2 norm of the model update **prior** to clipping. Finally, compute the mean $\\mu$ of the L2 norms from all of the 50 clients. You can find them in the history object returned in the \"all\" category of the metric. _NOTE: do not use the \"avg\" category because it is weighted._\n","\n","   > The results of this question will be used in the next one. Thus, to save yourself work, modify the strategy object. Make it compute the L2 norm of the overall model delta. This delta is defined as the difference between the federated model at the start of the round and the federated model after aggregation. Put the value of the L2 norm of the delta into the history object as a metric into the already aggregated metrics object. (The strategy has access to the starting parameters of a round in `configure_fit` as well as the aggregated metrics of all the clients.)\n","\n","2. Using values of `clip_norm`$\\in \\{ \\mu \\times 0.25,\\, \\mu, \\,\\mu \\times 1.75\\}$, run `DPFedAvgFixed` experiments with the same parameters as the example provided above using a `noise_multiplier=0`.\n","\n","3. Plot per-round accuracy on the federated test set of models trained using the three bounds above. Which bound converges the fastest and to the highest final accuracy, and why do you think that is?\n"]},{"cell_type":"markdown","metadata":{"id":"ABQ1eXfAHYgP"},"source":["**Question 4 (Part II ✅ | Part III/MPhil ✅):**\n","\n","(You must provide the answer with **code** and **plots** for this question. A short written argumentation is recommended.)\n","\n","This question extends the one above to investigate the effect that the `clip_norm` has upon the norm of the federated model update. The federated model update is defined as the difference between the model at the start of the round and the model post-aggregation.\n","\n","1. Using the results from the above question, plot the following:\n","\n","   - The L2 norm of the federated model deltas across rounds for the three bounds above. How does L2 norm of the federated model delta compare to `clip_norm` (draw a horizontal line for all three bounds)? Is the behaviour as you expected, and why/why not?\n","   - The accuracy on the federated test set of models trained using the three norms above against the cumulative L2 norm accumulated across rounds as the axis. Consider the accuracy of the initial parameter test (round 0) to map to an L2 norm of 0. By cumulative L2, we mean a running sum where you keep adding the new norm value to the sum and then add the sum to a per-round list. Such a sum can easily be computed from a list using a `accumulate()` call.\n","\n","2. How do the L2 norms of the federated model deltas compare against the change in accuracy between rounds? Is the relationship predictable and/or linear? Consider all the `clip_norm` values you have tried in your response and provide potential explanations for why/why not the relationship between accuracy and cumulative L2 changes between bounds.\n"]},{"cell_type":"markdown","metadata":{"id":"6LN_jrHXQsML"},"source":["## 3.2 Adaptive Norm Bound DP\n"]},{"cell_type":"markdown","metadata":{"id":"7gFxaCdKEaAY"},"source":["Having investigated the impact of gradient clipping with a fixed norm on performance, you may wonder if your chosen norm will stay appropriate for the entire training.\n","\n","To avoid perfectly tuning a fixed `clip_norm` an [adaptive version of DPFedAvg](https://arxiv.org/abs/1905.03871) was proposed in paper \\[3], which attempts to automatically scale the bound on the L2 norm of model updates based on a quantile of L2 norms provided by clients in a given round. As computing such a value would be computationally expensive and require clients to send private values, the paper proposes an algorithm meant to approximate the quantile.\n","\n","Specifically, it adjusts the `clip_norm` parameter as:\n","\n",">     self.clip_norm *= math.exp(-self.clip_norm_lr\n","\n","            * (noised_clients_with_clipped_norm_fraction - self.clip_norm_target_quantile)\n","        )\n","\n","where the new clip norm depends on a learning rate, the fraction of clients used in training who have clipped their norms (with added noise), and the target quantile. In the code below, the clients who have clipped their norm are reported via a set bit in the config, and thus `noised_clients_with_clipped_norm_fraction` is replaced with `noised_norm_bit_set_fraction`. By knowing approximately how many clients fall below a given norm, we can iteratively improve the `clip_norm` until the percentage of clients with norms smaller than the bound is reached.\n","\n","The new implementation is hard to use and balance for short experiments such as ours as it includes an initial phase where the norm grows exponentially in its attempts to converge to the actual quantile. Given that we do not want any further interference making the behaviour of DP harder to predict, this would prove inconvenient when trying to deduce the impact of noise. As such, we shall only track the behaviour of the adaptive norm and use the predictable `DPFedAvgFixed` when experimenting with obtaining a given level of $\\epsilon$ privacy.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aQYTCh8JQfQ6"},"outputs":[],"source":["\"\"\"DP-FedAvg [Andrew et al., 2019] with adaptive clipping.\n","Paper: https://arxiv.org/pdf/1905.03871.pdf\n","\"\"\"\n","\n","# Original implementation by Vasundhara Agarwal\n","\n","import math\n","from collections.abc import Callable\n","\n","import numpy as np\n","\n","from flwr.common import FitIns, FitRes, Parameters, Scalar\n","from flwr.server.client_manager import ClientManager\n","from flwr.server.client_proxy import ClientProxy\n","from flwr.server.strategy.strategy import Strategy\n","\n","\n","class DPFedAvgAdaptive(DPFedAvgFixed):\n","    \"\"\"Server-side adaptive clipping for DP-FedAvg.\"\"\"\n","\n","    # pylint: disable=too-many-arguments,too-many-instance-attributes\n","    def __init__(\n","        self,\n","        *,\n","        fraction_fit: float = 1.0,\n","        fraction_evaluate: float = 1.0,\n","        min_fit_clients: int = 2,\n","        min_evaluate_clients: int = 2,\n","        min_available_clients: int = 2,\n","        evaluate_fn: (\n","            Callable[\n","                [int, NDArrays, dict[str, Scalar]],\n","                tuple[float, dict[str, Scalar]] | None,\n","            ]\n","            | None\n","        ) = None,\n","        on_fit_config_fn: Callable[[int], dict[str, Scalar]] | None = None,\n","        on_evaluate_config_fn: Callable[[int], dict[str, Scalar]] | None = None,\n","        accept_failures: bool = False,\n","        initial_parameters: Parameters | None = None,\n","        fit_metrics_aggregation_fn: MetricsAggregationFn | None = None,\n","        evaluate_metrics_aggregation_fn: MetricsAggregationFn | None = None,\n","        server_learning_rate: float = 1.0,\n","        server_momentum: float = 0.0,\n","        num_clients_per_round: int,\n","        init_clip_norm: float = 0.1,\n","        noise_multiplier: float = 1,\n","        server_side_noising: bool = True,\n","        clip_norm_lr: float = 0.2,\n","        clip_norm_target_quantile: float = 0.5,\n","        clip_count_stddev: float | None = None,\n","    ) -> None:\n","        super().__init__(\n","            fraction_fit=fraction_fit,\n","            fraction_evaluate=fraction_evaluate,\n","            min_fit_clients=min_fit_clients,\n","            min_evaluate_clients=min_evaluate_clients,\n","            min_available_clients=min_available_clients,\n","            evaluate_fn=evaluate_fn,\n","            on_fit_config_fn=on_fit_config_fn,\n","            on_evaluate_config_fn=on_evaluate_config_fn,\n","            accept_failures=accept_failures,\n","            initial_parameters=initial_parameters,\n","            fit_metrics_aggregation_fn=fit_metrics_aggregation_fn,\n","            evaluate_metrics_aggregation_fn=evaluate_metrics_aggregation_fn,\n","            server_learning_rate=server_learning_rate,\n","            server_momentum=server_momentum,\n","            num_clients_per_round=num_clients_per_round,\n","            clip_norm=init_clip_norm,\n","            noise_multiplier=noise_multiplier,\n","            server_side_noising=server_side_noising,\n","        )\n","        self.clip_norm_lr = clip_norm_lr\n","        self.clip_norm_target_quantile = clip_norm_target_quantile\n","        self.clip_count_stddev = clip_count_stddev\n","\n","        # Decides the level of noise added to the fraction of clients which have clipped\n","        # their norms\n","        if self.clip_count_stddev is None:\n","            self.clip_count_stddev = 0\n","            if noise_multiplier > 0:\n","                self.clip_count_stddev = self.num_clients_per_round / 20.0\n","\n","        if noise_multiplier:\n","            self.noise_multiplier = (\n","                self.noise_multiplier ** (-2) - (2 * self.clip_count_stddev) ** (-2)\n","            ) ** (-0.5)\n","\n","    def configure_fit(\n","        self, server_round: int, parameters: Parameters, client_manager: ClientManager\n","    ) -> list[tuple[ClientProxy, FitIns]]:\n","        \"\"\"Configure the next round of training.\"\"\"\n","        additional_config = {\"dpfedavg_adaptive_clip_enabled\": True}\n","\n","        client_instructions = super().configure_fit(\n","            server_round, parameters, client_manager\n","        )\n","\n","        for _, fit_ins in client_instructions:\n","            fit_ins.config.update(additional_config)\n","\n","        return client_instructions\n","\n","    def _update_clip_norm(self, results: list[tuple[ClientProxy, FitRes]]) -> None:\n","        \"\"\"Update the clipping norm based on the fraction of clients which clipped.\"\"\"\n","        # Calculating number of clients which set the norm indicator bit\n","        norm_bit_set_count = 0\n","        for client_proxy, fit_res in results:\n","            if \"dpfedavg_norm_bit\" not in fit_res.metrics:\n","                raise Exception(\n","                    f\"Indicator bit not returned by client with id {client_proxy.cid}.\"\n","                )\n","            if fit_res.metrics[\"dpfedavg_norm_bit\"]:\n","                norm_bit_set_count += 1\n","        # Noising the count\n","        noised_norm_bit_set_count = float(\n","            np.random.normal(norm_bit_set_count, self.clip_count_stddev)\n","        )\n","\n","        noised_norm_bit_set_fraction = noised_norm_bit_set_count / len(results)\n","        # Geometric update\n","        self.clip_norm *= math.exp(\n","            -self.clip_norm_lr\n","            * (noised_norm_bit_set_fraction - self.clip_norm_target_quantile)\n","        )\n","\n","    def aggregate_fit(\n","        self,\n","        server_round: int,\n","        results: list[tuple[ClientProxy, FitRes]],\n","        failures: list[tuple[ClientProxy, FitRes] | BaseException],\n","    ) -> tuple[Parameters | None, dict[str, Scalar]]:\n","        \"\"\"Aggregate the results of the training round.\"\"\"\n","        if not self.accept_failures and failures:\n","            return None, {}\n","        new_global_model, metrics = super().aggregate_fit(\n","            server_round, results, failures\n","        )\n","        self._update_clip_norm(results)\n","        metrics[\"adaptive_clip_norm\"] = self.clip_norm\n","        return new_global_model, metrics"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"di5e_PszSLUg"},"outputs":[],"source":["# New function to run the adaptive norm experiments with sensible defaults\n","\n","dp_client_generator = get_DP_client_generator(\n","    network_generator_cnn,\n","    data_dir,\n","    federated_partition,\n","    lambda x: client_samples_dataframe.cid[x],\n",")\n","\n","\n","adaptive_default_parameters: dict = {\n","    \"train_config\": get_default_train_config(),\n","    \"test_config\": get_default_test_config(),\n","    \"num_total_clients\": num_total_clients,\n","    \"num_clients_per_round\": 4,\n","    \"num_evaluate_clients\": 0,\n","    \"num_evaluate\": 0,\n","    \"accept_failures\": False,\n","    \"min_fit_clients\": 2,\n","    \"min_available_clients\": 2,\n","    \"initial_parameters\": ndarrays_to_parameters(seed_model_cnn_params),\n","    \"client_generator\": dp_client_generator,\n","    \"seed\": Seeds.DEFAULT,\n","    \"num_rounds\": 30,\n","    \"strategy\": DPFedAvgAdaptive,\n","    \"fed_eval\": True,\n","    \"server_side_noising\": True,\n","    \"clip_count_stddev\": None,\n","}\n","\n","\n","def run_DP_adaptive_fl(\n","    noise_multiplier: float = 0,\n","    init_clip_norm: float = 2,\n","    clip_norm_lr: float = 0.2,\n","    clip_norm_target_quantile: float = 0.5,\n","    default_parameters: dict = adaptive_default_parameters,\n","    **kwargs: dict[str, Any],\n",") -> Any:\n","    \"\"\"Execute a DP-FedAvg simulation with adaptive clipping.\"\"\"\n","    parameters: dict = {**default_parameters, **kwargs}\n","\n","    def on_fit_config_fn(cid: int) -> dict[str, Scalar]:\n","        return parameters[\"train_config\"]\n","\n","    def on_evaluate_config_fn(cid: int) -> dict[str, Scalar]:\n","        return parameters[\"test_config\"]\n","\n","    fraction_fit: float = (\n","        float(parameters[\"num_clients_per_round\"]) / parameters[\"num_total_clients\"]\n","    )\n","    fraction_evaluate: float = (\n","        float(parameters[\"num_evaluate_clients\"]) / parameters[\"num_total_clients\"]\n","    )\n","\n","    strategy = parameters[\"strategy\"](\n","        num_clients_per_round=parameters[\"num_clients_per_round\"],\n","        fraction_fit=fraction_fit,\n","        fraction_evaluate=fraction_evaluate,\n","        min_fit_clients=parameters[\"min_fit_clients\"],\n","        min_available_clients=parameters[\"min_available_clients\"],\n","        on_fit_config_fn=on_fit_config_fn,\n","        on_evaluate_config_fn=on_evaluate_config_fn,\n","        initial_parameters=parameters[\"initial_parameters\"],\n","        accept_failures=parameters[\"accept_failures\"],\n","        evaluate_fn=(\n","            federated_evaluation_function if parameters[\"fed_eval\"] is True else None\n","        ),\n","        fit_metrics_aggregation_fn=aggregate_weighted_average,\n","        evaluate_metrics_aggregation_fn=aggregate_weighted_average,\n","        init_clip_norm=init_clip_norm,\n","        clip_norm_lr=clip_norm_lr,\n","        clip_norm_target_quantile=clip_norm_target_quantile,\n","        noise_multiplier=noise_multiplier,\n","        server_side_noising=parameters[\"server_side_noising\"],\n","        clip_count_stddev=parameters[\"clip_count_stddev\"],\n","    )\n","    client_manager = CustomClientManager(criterion=None, seed=parameters[\"seed\"])\n","    server = Server(\n","        client_manager=client_manager,\n","        strategy=strategy,\n","    )\n","    return start_seeded_simulation(\n","        client_fn=lambda cid: parameters[\"client_generator\"](cid).to_client(),\n","        num_clients=parameters[\"num_total_clients\"],\n","        server=server,\n","        config=ServerConfig(num_rounds=parameters[\"num_rounds\"]),\n","        strategy=strategy,\n","        seed=parameters[\"seed\"],\n","        name=f\"adaptive_target_{clip_norm_target_quantile}_init_clip_norm_{init_clip_norm}_lr_{clip_norm_lr}_noise_{noise_multiplier}\",\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29149,"status":"ok","timestamp":1703272364237,"user":{"displayName":"Alexandru-Andrei Iacob","userId":"00751686620367198202"},"user_tz":-120},"id":"X0WoSm7mp0u4","outputId":"707004b9-5527-4ca2-bb22-4171f8d60b7a"},"outputs":[],"source":["parameters_for_every_round, hist_adaptive_quantile_0_5 = run_DP_adaptive_fl(\n","    clip_norm_target_quantile=0.5, noise_multiplier=0\n",")"]},{"cell_type":"markdown","metadata":{"id":"UxBjz9Ibp0u4"},"source":["Having gone through this slight detour to understand how we could obtain an adaptive bound which leaves the privacy budget mostly undisturbed without experimentation, we shall return to DP's primary goal, matching a given theoretical bound on privacy. However, Part III and MPhil students will now get to play around and observe the behaviour of this adaptive norm algorithm.\n"]},{"cell_type":"markdown","metadata":{"id":"6NUMToSfJMIB"},"source":["**Question 5 (Part III/MPhil ✅):**\n","\n","(You need to provide the answer with **code** and **plots** for this question. A short written argumentation is recommended.)\n","\n","You will now examine the accuracy of adaptive norm clipping compared to the previously fixed norm clipping.\n","\n","1. Using values of `clip_norm_target_quantile`$\\in \\{0.125,\\, 0.5, \\,0.875\\}$ (you should already have results for the default value from the cells above. If you have lost it, look into the `histories` folder). Run `DPFedAvgAdaptive` experiments with the same parameters as the above example using a `noise_multiplier=0`.\n","2. Plot the per-round accuracy on the federated test set of models trained using the three quantile targets above. Which quantile target converges the fastest and to the highest final accuracy, and why do you think that is? Are the results as conclusive as the fixed bound ones? **Hint**: consider the exponential nature of the bound adaptation.\n","3. Do an ordered pairwise comparison between the plots of per-round accuracy of the previous three `clip_norm` results for the fixed norm experiments against the adaptive norm experiments, i.e., plot `clip_norm=mean*0.25` against `clip_norm_target_quantile=0.125`, `clip_norm=mean` against `clip_norm_target_quantile=0.5`, and `clip_norm=mean*1.75` against `clip_norm_target_quantile=0.875`. How does each of the pairs compare? Where are the differences most pronounced, and why do you think that is?\n"]},{"cell_type":"markdown","metadata":{"id":"8pMrcr09LHMR"},"source":["**Question 6 (Part III/MPhil ✅):**\n","\n","(You need to provide the answer with **code** and **plots** for this question. A short written argumentation is recommended.)\n","\n","This is an extension to the previous question, which tries to expand upon how the adaptive norm applied to client gradients/updates affects the L2 norm of the federated model delta.\n","\n","1. Using the previous results for `clip_norm_target_quantile`$\\in \\{0.125,\\, 0.5, \\,0.875\\}$, plot the L2 norm of the federated model delta for each target quantile. Which of the target quantiles causes the most considerable oscillations in the federated L2 norm, and why do you think that is?\n","2. Do a similar ordered pairwise comparison between the federated L2 norm results of the target quantile experiments against those of the fixed bound experiments as in the previous question. Where is the gap between the adaptive and fixed method the largest?\n","3. Plot the accuracy of experiments with the adaptive bounds against the cumulative L2 norm.\n"]},{"cell_type":"markdown","metadata":{"id":"Mcj40lI_p0u4"},"source":["# 4 Epsilon-delta Privacy\n"]},{"cell_type":"markdown","metadata":{"id":"z8sCwQPIJ-sM"},"source":["We are now ready to understand the full extent of the DPFedAvg fixed algorithm and the relation between its privacy guarantees and the accuracy of the final model.\n","\n","Before this, we should establish what a particular set of DP parameters implies for the level of privacy theoretically. The function below shall allow us to do just that while assuming a fixed number of rounds and clients per round. It adapts a function provided by TensorFlow privacy for DP-SGD, as we have established that DP-FedAvg and DP-SGD are equivalent when considering a mere reframing of samples as clients; it should provide sufficient accuracy for our purposes.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zDGDh5TrCrqQ"},"outputs":[],"source":["from tensorflow_privacy.privacy.analysis.compute_dp_sgd_privacy_lib import (\n","    compute_dp_sgd_privacy,\n",")\n","from contextlib import redirect_stdout\n","from io import StringIO\n","\n","\n","class NullIO(StringIO):\n","    \"\"\"Custom IO interface to cut-out annoying messages.\"\"\"\n","\n","    def write(self, txt: str) -> None:\n","        \"\"\"Implement custom empty write function.\"\"\"\n","        # This function intentionally does nothing\n","\n","\n","def compute_fl_privacy(\n","    num_rounds: int = 25,\n","    noise_multiplier: float = 1.0,\n","    num_total_clients: int = num_total_clients,\n","    num_fit_clients: int = 4,\n",") -> float:\n","    \"\"\"Compute the privacy bound `epsilon`.\"\"\"\n","    with redirect_stdout(NullIO()):\n","        vals = compute_dp_sgd_privacy(\n","            n=num_total_clients,\n","            batch_size=num_fit_clients,\n","            noise_multiplier=noise_multiplier,\n","            epochs=num_rounds,\n","            delta=num_total_clients ** (-1),\n","        )\n","    return vals[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1703272168937,"user":{"displayName":"Alexandru-Andrei Iacob","userId":"00751686620367198202"},"user_tz":-120},"id":"rYJEgCF1DT0m","outputId":"20e788db-80a7-4fdf-c389-5309a8115685"},"outputs":[],"source":["log(INFO, compute_fl_privacy(noise_multiplier=0.05))\n","log(INFO, compute_fl_privacy(noise_multiplier=0.1))"]},{"cell_type":"markdown","metadata":{"id":"34ps0e91FLmz"},"source":["**Question 7 (Part II ✅ | Part III/MPhil ✅):**\n","\n","(While this is a largely conceptual question, it does require you to provide a small amount of **code** and several **plots**. Answers to the purely conceptual components should contain **no more than 5 sentences**.)\n","\n","Using the function mentioned above, study the impact of different parameters on the privacy guarantees of DP-FedAvg as follows:\n","\n","1. Draw a scatter plot with the epsilon value on the y-axis. While keeping all the other parameters constant to the above values, vary the noise multiplier from 0.05 to 2 using an increment of 0.05. Use the noise multiplier as the x-axis.\n","\n","2. Draw a scatter plot with the epsilon value on the y-axis. While keeping all the other parameters constant to the above values, vary `num_rounds` between $2^0$ and $2^{15}$ increasing using all the powers of two in the interval. Use the `num_rounds` as the x-axis.\n","\n","3. Draw a scatter plot with the epsilon value on the y-axis. While keeping all the other parameters constant to the above values, vary `num_fit_cliets` from $2^0$ to $2^{10}$ increasing using all the powers of two in the interval. Use the `num_fit_cliets` as x-axis.\n","\n","4. Describe the trade-offs you see and how they relate to FL privacy. <!-- Then, given the lecture by Peter Kairouz, what do you think the implications of these trade-offs are upon the practicality of Differential Privacy in FL? --> Then, what do you think are the implications of these trade-offs upon the practicality of differential privacy in FL?\n"]},{"cell_type":"markdown","metadata":{"id":"kq-aIzEop0u4"},"source":["Armed with this theoretical understanding of the privacy budget, we can explore the performance implications of Differential Privacy upon DPFedAvgFixed. Note once more that the experiments we are running are small scale, as such you may find particularly high sensitivity to the `noise_multiplier` to be present.\n"]},{"cell_type":"markdown","metadata":{"id":"sMv9vxDcpHJy"},"source":["**Question 8 (Part II ✅ | Part III/MPhil ✅):**\n","\n","(You need to provide the answer with **code** and **plots** for this question. A short written argumentation is recommended.)\n","\n","Using the results of the previous experiment, observe the impact that a given noise multiplier has on both performance and privacy when using a **fixed** norm bound.\n","\n","1. Set a `noise_multiplier`$\\in \\{0.1\\}$ while keeping all other parameters constant. Then run the FL simulation using the `DPFedAvgFixed` strategy from above.\n","\n","2. Plot accuracy and compare the convergence curves against the results you have for the previous experiment with a multiplier of $0.05$ (`hist_clip_bound_4_noise_0_05`). _NOTE: it was done just after defining the aforementioned strategy._\n","\n","3. Use the `compute_fl_privacy` function to compute the epsilon value of two noise levels mentioned above. How does the epsilon of a given noise level relate to the accuracy achieved by that model? Does the relationship between the two fit your expectations from the question above?\n"]},{"cell_type":"markdown","metadata":{"id":"aECReucy64EK"},"source":["# End of Part I\n","\n","Continue to part 2.\n"]},{"cell_type":"markdown","metadata":{"id":"hlzTFkkwRob8"},"source":["(c) 2024 Alexandru-Andrei Iacob, Lorenzo Sani\n"]}],"metadata":{"colab":{"provenance":[{"file_id":"1_j2Gpn6gqpWA5KJkbkhZh5_rQyLLx2-a","timestamp":1676991800894},{"file_id":"1aAIM403hPVDGafDmq7Q00t57LX0VvpDv","timestamp":1676667921796}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"vscode":{"interpreter":{"hash":"f60f5a2c15992c74df12f0554524b987217e124a6a47cf1bc494002bece5a18b"}}},"nbformat":4,"nbformat_minor":0}
